### 什么是持续集成
持续集成（CI）
在持续集成的环境中，开发人员将会频繁的提交代码到主干。这些新提交在最终合并到主线之前，都需要通过编译和自动化测试流进行验证。这样做是基于之前的持续集成过程中很重视自动化测试验证结果，1以保证所有的提交在合并主干的质量问题，对可能出现的一些问题进行预警。

我们之前的流程是，我完成一个模块，然后人工告知QA说，我这边解决了，然后QA开始测试，出了问题，被打回，然后继续改，继续测，两个人疯狂的在那里打太极，严重降低了效率。
所以我们加入了持续集成（CI）.每一次，当前端代码提交到主线上的时候，都会自动跑自动化测试，等到自动化脚步跑了没错之后，才会合并到主分支，然后发消息通知QA来介入，这样就减少了很多QA和前端的交互

自动化提交代码，是程序员将代码提交到远程的一个服务器上，然后这个服务器上部署着webpack啊，自动化测试的脚本等等，然后等整个项目通过了自动化测试的脚本之后，然后通知测试，这时测试只负责一部分必须测试的内容，测试完通过之后，然后交付给CD,CD开始自动化部署

**持续部署（continuous deployment）简称CD**
- 如果我们想更加深入的话，就是持续部署了。通过这个方式，任何修改通过所有已有的工作流就会直接和客户见面。没有认为的干预（没有一键部署按钮），只有当一个修改在工作流中构建失败才能阻止他部署到生产线上
- 持续部署是一个很优秀的方式，可以加速与客户的反馈循环，但是会给团队带来压力，因为再也没有“发布日”了。开发人员可以专注于构建软件，他们看到他们的修改在他们完成工作的几分钟内就上线了，基本上，当开发人员在主分支合并一个提交时，这个分支将被构建、测试，如果一切顺利，则部署到生产环境上。

这个方法就在线下测试通过了，然后通过测试脚本，就会直接往线上部署，代替线上的代码。这样的过程对团队的压力很大，对公司的人员的硬实力要求很高。
实现这个方法的平台有：devops  可以理解成（softenginer,qa,technology operations）三个东西合并在一起了。这个东西最重要的部分就是CI


**持续交付（continuous delivery）**
- 持续交付就是讲我们的应用发布出去的过程，这个过程可以确保我们尽可能快的实现交付。这就意味着除了自动化测试，我们还需要自动化的发布流以及通过一个按钮就可以随时随地的实现应用的部署上线。
- 通过持续交付，你可以决定每天，每周，每两周发布一次，完全可以根据自己的业务进行设置
- 如果真的希望体验到持续交付的优势，就需要进行小批量的发布，尽快部署到生产线上，以便出现问题的时方便进行故障排除。


**持续集成的需求**
1. 持续集成是通过平台串联各个开发环节，实现和沉淀工作自动化的方法
2. 线上代码和代码仓库不同步，影响迭代和团队协作
3. 静态资源发布依赖人工，浪费开发人力
4. 缺少自动化测试，产品质量得不到保障
5. 文案简单修改上线，需要技术的介入。

一个项目上线的流程

![](https://github.com/4lQuiorrA/FE_Journey/blob/master/image/node/chixujichengliucheng.png)

- 首先立项
- 然后产品经历采集需求，需求文档编写完成之后，将需求文档放入到代码仓库里面
- 然后开发人员通过需求文档开发完了整个项目的代码，将代码放入到代码仓库里面
- 然后自动化构建平台就会从项目的代码仓库里面拉取代码（gitlab 既可以上传svn，也能上传git项目），拉取完代码之后，构建平台调用各色的构建工具（webpack,fis）之类的，开始对项目进行编译打包，项目构建完之后，部署到内网环境中，然后发消息通知qa去测试，qa开始测试自己的测试用例，测试通过之后，开始部署到外网环境，然后在运维和开发之间有个特殊的用户运营产品研发，这个角色，将体验用户带到特定的场所中，使用特殊的工具（如腾讯的：眼动仪），采集到用户的手喜欢点击整个屏幕的那个地方，和眼睛注意的主要区域。将这些信息采集完成之后，然后通知产品，针对这些内容再次进行需求修改，最后通知ui动画，重新设计，开发人员开始更改，最后重复自动化流程，最后上线。

**如果想要通过这个方式来构建项目需要以下的条件**
- 统一的代码仓库通过分支管理合并主干svn
- 自动化构建工具，编译，部署，测试，监控，本机开发上线环境。如：fis3/webpack/jdists/package.json//chai/supertest/mocha/selenium-webdriver
- 持续化集成平台：jenkins,travis ci
- 部署工具：rsync,shelljs,yargs
- 运营同学有权限操作运营页面保存即可上线。


### 什么是统一代码仓库
**SVN项目开发阶段图示**

![](https://github.com/4lQuiorrA/FE_Journey/blob/master/image/node/svnxiangmukaifajieduan.png)

正确的流程是
1. 开发人员A从主分支上，拉一个分支 A01,开发人员B从主分支上，拉一个分支A02
2. 开发人员A开发完，测试完没问题，将分支merge到主分支上，打上版本Tag ,然后开发人员B需要从主分支上pull下来代码，进行第一次merge后，才能push到主分支上，然后打上版本tag

tag:代码标签，方便代码回滚。
**svn的使用步骤**
- SVN checkout svn地址 --username 用户名
- svn branch 分支名 （可以进行add ,commit ）
- svn merge 主干svn地址 分支svn地址
- Beyond  Compare  -> svn resolved.  解决合并分支的时候的冲突
- svn copy 主干svn /tags/2017  

**当然这些命令不仅仅可以直接用来手动输入，可以通过`shelljs`模块在nodejs中自己搭建一个进程，然后能够自动化的执行这些命令**

```
const shell = reqire('shelljs')
exports.createBranch  = function(req,resp){
    sheel.exec("git branch"+req.params.name); // 从主分支中拉出一个名为req.params.name 的分支
    console.log(shell.exec('git checkout '+req.params.name).code); // 并且切到这个分支
    console.log(shell.exec('git push origin '+req.params.name).code);
    res.json(successMessage);
}
```

### 前端工程化的目标
- 自动化编译
- 前端模块化
- 定位前端资源
- 前端开发组件化
- 自动化部署测试配合版本库
- 自动化性能优化（前端架构开发下）

**自动化编译的流程**

1. 读入foo.es文件内容，编译成js内容
2. 分析js内容，找到资源定位标记‘foo.scss’
3. 对foo.scss进行编译
    1. 读入foo.scss的文件内容进行编译，编译成css内容
    2. 分析css内容，找到资源定位标记''url(foo.png)''
    3. 对foo.png进行编译
        1. 读入foo.png的内容
        2. 图片压缩
        3. 返回图片内容
    4. 根据foo.png的最终目标计算md5戳，替换url('foo.png')为url('/static/img/foo_2afob.png');
    5. 替换完所有资源定位标记，对css内容进行压缩
    6. 返回css内容
4. 根据foo.css的最终内容计算md5戳，替换`foo.css`为`/static/scss/foo_bae39.css`
5. 替换完所有的资源定位标记，对js内容进行压缩
6. 返回js内容
7. 根据最终的js内容，得到foo.coffee的资源url为`/static/scripts/foo.efc20.js`

#### 前端模块化
- 前端模块化肩负着模块管理，资源家在两项重要的功能，这两项功能与工具、性能、业务、部署等工程环节都有着非常紧密的联系。因此模块化框架的设计应该最高优先级考虑工程需要
- CommonJs API 定义很多普通应用程序（主要指非浏览器的应用）使用的API，从而填补了这个空白。他的终极目标是提供一个类似Python、Ruby和java标准库
- 根据这个规范，每个文件就是一个模块，有自己的模块，有自己的作用域。在一个文件里面定义的变量、函数、类、都是私有的，对其他文件不可见
- **Cmd和AMD都是Commonjs的一种规范的定义，Requirejs和seajs是对应的实践**


**CommonJs**
Commonjs定义的模块分为：{模块引用（require）}{模块定义（exports）}{模块标识（module）}
require()用来引入外部模块；exports对象用于导出当前模块的方法或者变量，唯一导出口；module对象就代表导出模块本身

node以及webpack就是使用了`commonjs`规范作为模块管理。

**AMD(Asynchronous Module Definition 异步模块加载)**

`AMD`也采用`require()`语句加载模块，但不同于Commonjs,他要求两个参数

```
require(「module」,callback)
```
cmd讲究的就是，我把所有的需要加载的模块都拿下来，然后，在我的里面，你只能使用这些已经在加载过了的模块，也不准你再次的去加载其他模块

RequireJs就是实现了AMD规范

RequireJs的使用场景分析
1. 最早的时候，所有javascript的代码都写在一个文件里面，只要加载一个文件就够了。后来代码越来越多，一个文件不够了，必须分为多个js文件一次加载。

**CMD**



```
define(function(require,exports,module){
    var xxx  = require('xxx');
})

CMD更加讲究的是我现用先拿，我把require，exports,module给你提供了，你要用什么模块，直接加载什么模块就好了，这比较像nodejs
```

**CMD和AMD的优缺点**
1. cmd依赖的是就近声明，通过内部require方法进行声明。但是因为是异步模块，加载器需要提前加载这些模块，所以模块真正的使用前需要提取模块里面所有的模块
2. 不能直接压缩，require局部变量如果替换无法加载资源
3. cmd路径不能进行字符串运算
4. AMD的依赖需要提前声明。这种优势的好处就是依赖无需通过静态分析，无论是加载器还是自动化工具都可以直接获取到依赖
5. AMD依赖提前声明在代码书写上非常友好🍎
6. AMD模块内部与NodeJs的module有一定的差异

分析：cmd加载器要去找到所有的模块，通过正则去匹配所有require()上的内容，所以当把`var xxx = require("xxx")`这段代码注释掉，这段代码的导入依然是生效的。

**接下来是一段require编译后的转换情况**


```
//footer.es文件
require('a.es')

//->转换后
// a.es->a.xxx555ff.js
;define('common:widget/footer/footer.es',function(){
    // a.xxx555ff.js
})
```

define是AMD的规定的一个函数，如果要使用AMD规范，就必须采用特定的`define()`函数来定义，如果一个模块不依赖其他模块，那么可以直接定义在`define()`函数之中。
```
// math.js
define(function(){
    var add  = function(x,y){
        return x+y;
    }
    return {
        add:add
    }
})

// 加载方法
require(['math'],function(math){
    alert(math(1,1));
})
```
这里由于整个`math.js`文件并不会依赖任何内容所以`math.js`模块可以直接定义在`define`函数内

### webpack

为什么要使用webpack
- webpack执行commonjs标准，解决了依赖配置和请求流量
- 对于webpack来讲万物都可以是模块，所有的文件都被合并到JS中，最终在浏览器中执行。
- 兼容AMD和CMD
- JS模块化不仅仅为了提高代码复用性，更是为了让资源文件更合理的进行缓存

### 静态资源定位

什么是静态资源定位
1. 刚开始学前端的时候，写个静态页面引一个css，开开心心上线



### 什么是自动化构建
