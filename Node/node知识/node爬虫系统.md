### 爬虫
是一种自动获取网页内容的程序。是搜索引擎的重要组成部分，因此搜索引擎优化很大程度就是针对爬虫而做出的优化。

### robots协议
robots协议是搜索引擎中非常中要的协议，其实robots协议就是一个文本文件`robots.txt`,`robots.txt`，是一个协议，而不是命令。`robots.txt`是爬虫要查看的第一个文件。`robots.txt`文件告诉爬虫服务器上什么文件是可以被查看的，搜索机器人就会按照该文件中的内容来确定访问范围，如果你通过爬虫系统爬取了用户不可访问的内容，这就涉及到法律的范畴，所以，我们需要界定搜索机器人能访问的内容。

爬虫系统就是：我们从`browsers`获取到我们想要的内容，然后给到我们自己的`websites`之后再将爬取到的信息，放到目标`source Websites`